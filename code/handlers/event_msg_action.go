package handlers

import (
	"encoding/json"
	"fmt"
	"start-feishubot/services/openai"
	"start-feishubot/utils"
	"strings"
)

type MessageAction struct { /*æ¶ˆæ¯*/
}

func (*MessageAction) Execute(a *ActionInfo) bool {
	// Handle confirmation command to proceed with web search from previous suggestion
	trimmed := strings.TrimSpace(a.info.qParsed)
	if trimmed == "/search" || trimmed == "ç»§ç»­è”ç½‘" || trimmed == "ç»§ç»­" {
		history := a.handler.sessionCache.GetMsg(*a.info.sessionId)
		// find last assistant message containing CONFIRM_WEB payload
		var payloadJSON string
		for i := len(history) - 1; i >= 0; i-- {
			if history[i].Role != "assistant" {
				continue
			}
			idx := strings.LastIndex(history[i].Content, "CONFIRM_WEB:")
			if idx >= 0 {
				payloadJSON = strings.TrimSpace(history[i].Content[idx+len("CONFIRM_WEB:"):])
				break
			}
		}
		if payloadJSON == "" {
			// nothing to confirm, continue normal flow
		} else {
			type confirmPayload struct {
				Question string   `json:"question"`
				Queries  []string `json:"queries"`
			}
			var cp confirmPayload
			if err := json.Unmarshal([]byte(payloadJSON), &cp); err == nil {
				// perform the same second-stage logic as auto path
				queries := cp.Queries
				if len(queries) == 0 {
					queries = []string{cp.Question}
				}
				fmt.Println("[Second Stage Confirmed] queries:", queries)
				maxQ := 3
				if len(queries) < maxQ {
					maxQ = len(queries)
				}
				var ctxParts []string
				for i := 0; i < maxQ; i++ {
					q := strings.TrimSpace(queries[i])
					if q == "" {
						continue
					}
					ctx, err := utils.BuildSearchContext(q, 3)
					if err != nil || strings.TrimSpace(ctx) == "" {
						continue
					}
					ctxParts = append(ctxParts, fmt.Sprintf("{\"query\": %q, \"sources\": %s}", q, ctx))
				}
				fmt.Println("[Second Stage Confirmed] built contexts:", len(ctxParts))
				if len(ctxParts) == 0 {
					if err := replyMsg(*a.ctx, "å°è¯•è”ç½‘æ£€ç´¢æœªè·å–åˆ°æœ‰æ•ˆèµ„æ–™ï¼Œè¯·ç¨åå†è¯•ã€‚", a.info.msgId); err != nil {
						replyMsg(*a.ctx, fmt.Sprintf("ğŸ¤–ï¸ï¼šæ¶ˆæ¯æœºå™¨äººæ‘†çƒ‚äº†ï¼Œè¯·ç¨åå†è¯•ï½\né”™è¯¯ä¿¡æ¯: %v", err), a.info.msgId)
					}
					return false
				}
				contextJSON := "[" + strings.Join(ctxParts, ",") + "]"
				webSystem := openai.Messages{Role: "system", Content: "ä½ æ˜¯ä¸€ä¸ªè”ç½‘åŠ©æ‰‹ã€‚æ ¹æ®ç»™å®šçš„æ£€ç´¢èµ„æ–™ï¼ˆJSON æ•°ç»„ï¼Œå« query ä¸ sources åˆ—è¡¨ï¼Œæ¯ä¸ª source æœ‰ titleã€urlã€contentï¼‰ï¼Œè¯·ä¸¥è°¨å›ç­”ç”¨æˆ·é—®é¢˜ï¼š\n- ä»…ä½¿ç”¨èµ„æ–™ä¸­èƒ½å¤Ÿæ”¯æŒçš„äº‹å®ï¼›\n- ä¸ç¡®å®šæ—¶æ˜ç¡®è¯´æ˜ä¸ç¡®å®šï¼›\n- åœ¨å†…å®¹æœ«å°¾åˆ—å‡ºå¼•ç”¨çš„ç½‘å€åˆ—è¡¨ã€‚"}
				userWithCtx := openai.Messages{Role: "user", Content: fmt.Sprintf("ç”¨æˆ·é—®é¢˜ï¼š%s\næ£€ç´¢èµ„æ–™(JSON)ï¼š%s", cp.Question, contextJSON)}
				secondMsgs := append(history, webSystem)
				secondMsgs = append(secondMsgs, userWithCtx)
				finalResp, err := a.handler.gpt.Completions(secondMsgs)
				if err != nil {
					replyMsg(*a.ctx, fmt.Sprintf("ğŸ¤–ï¸ï¼šæ¶ˆæ¯æœºå™¨äººæ‘†çƒ‚äº†ï¼Œè¯·ç¨åå†è¯•ï½\né”™è¯¯ä¿¡æ¯: %v", err), a.info.msgId)
					return false
				}
				fmt.Println("[OpenAI Second] raw:", finalResp.Content)
				finalHistory := append(history, openai.Messages{Role: "user", Content: cp.Question})
				finalHistory = append(finalHistory, openai.Messages{Role: "assistant", Content: finalResp.Content})
				a.handler.sessionCache.SetMsg(*a.info.sessionId, finalHistory)
				if len(finalHistory) == 2 {
					sendNewTopicCard(*a.ctx, a.info.sessionId, a.info.msgId, finalResp.Content)
					return false
				}
				if err := replyMsg(*a.ctx, finalResp.Content, a.info.msgId); err != nil {
					replyMsg(*a.ctx, fmt.Sprintf("ğŸ¤–ï¸ï¼šæ¶ˆæ¯æœºå™¨äººæ‘†çƒ‚äº†ï¼Œè¯·ç¨åå†è¯•ï½\né”™è¯¯ä¿¡æ¯: %v", err), a.info.msgId)
					return false
				}
				return true
			}
		}
		// if no payload, fall through to normal flow
	}
	// Step 1: classification â€“ decide if we need web and extract key queries
	type webDecision struct {
		NeedWeb bool     `json:"need_web"`
		Queries []string `json:"queries,omitempty"`
		Answer  string   `json:"answer,omitempty"`
		Reason  string   `json:"reason,omitempty"`
	}

	// Build classification prompt
	classifySystem := openai.Messages{Role: "system", Content: "ä½ æ˜¯ä¸€ä¸ªåŠ©æ‰‹ã€‚è¯·ä¸¥æ ¼è¾“å‡º JSONï¼Œä¸è¦åŒ…å«å¤šä½™æ–‡æœ¬ã€‚æ ¹æ®ç”¨æˆ·é—®é¢˜åˆ¤æ–­æ˜¯å¦éœ€è¦è”ç½‘æ£€ç´¢å¤–éƒ¨ä¿¡æ¯æ‰èƒ½ç»™å‡ºå¯é ç­”æ¡ˆã€‚è‹¥éœ€è¦ï¼Œè¯·ç»™å‡º3-6æ¡ç²¾ç‚¼çš„ä¸­æ–‡æ£€ç´¢å…³é”®ä¿¡æ¯ï¼ˆqueriesï¼‰ã€‚è‹¥ä¸éœ€è¦ï¼Œè¯·ç›´æ¥ç»™å‡ºæœ€ç»ˆç­”æ¡ˆã€‚å¿…é¡»è¾“å‡ºå¦‚ä¸‹ JSONï¼š{\"need_web\": boolean, \"queries\": string[], \"answer\": string}. å½“ need_web=true æ—¶ï¼Œå°½é‡å¡«å†™ queriesï¼Œanswer å¯ç•™ç©ºï¼›å½“ need_web=false æ—¶ï¼Œå¿…é¡»å¡«å†™ answerï¼Œqueries å¯ç•™ç©ºã€‚"}

	history := a.handler.sessionCache.GetMsg(*a.info.sessionId)
	classifyMsgs := append([]openai.Messages{classifySystem}, history...)
	classifyMsgs = append(classifyMsgs, openai.Messages{Role: "user", Content: a.info.qParsed})

	clsResp, err := a.handler.gpt.Completions(classifyMsgs)
	if err != nil {
		replyMsg(*a.ctx, fmt.Sprintf(
			"ğŸ¤–ï¸ï¼šæ¶ˆæ¯æœºå™¨äººæ‘†çƒ‚äº†ï¼Œè¯·ç¨åå†è¯•ï½\né”™è¯¯ä¿¡æ¯: %v", err), a.info.msgId)
		return false
	}
	// debug: print first-stage raw output
	fmt.Println("[OpenAI First] raw:", clsResp.Content)

	var decision webDecision
	if err := json.Unmarshal([]byte(clsResp.Content), &decision); err != nil {
		// Fallback: if not valid JSON, use original single-shot behavior
		msg := append(history, openai.Messages{Role: "user", Content: a.info.qParsed})
		completions, err2 := a.handler.gpt.Completions(msg)
		if err2 != nil {
			replyMsg(*a.ctx, fmt.Sprintf("ğŸ¤–ï¸ï¼šæ¶ˆæ¯æœºå™¨äººæ‘†çƒ‚äº†ï¼Œè¯·ç¨åå†è¯•ï½\né”™è¯¯ä¿¡æ¯: %v", err2), a.info.msgId)
			return false
		}
		// debug: print single-shot raw output
		fmt.Println("[OpenAI Single] raw:", completions.Content)
		// append to history as final answer
		msg = append(msg, completions)
		a.handler.sessionCache.SetMsg(*a.info.sessionId, msg)
		// new topic card logic
		if len(msg) == 2 {
			sendNewTopicCard(*a.ctx, a.info.sessionId, a.info.msgId, completions.Content)
			return false
		}
		if err = replyMsg(*a.ctx, completions.Content, a.info.msgId); err != nil {
			replyMsg(*a.ctx, fmt.Sprintf("ğŸ¤–ï¸ï¼šæ¶ˆæ¯æœºå™¨äººæ‘†çƒ‚äº†ï¼Œè¯·ç¨åå†è¯•ï½\né”™è¯¯ä¿¡æ¯: %v", err), a.info.msgId)
			return false
		}
		return true
	}
	if b, _ := json.Marshal(decision); len(b) > 0 {
		fmt.Println("[Decision JSON]:", string(b))
	}

	if decision.NeedWeb {
		// æ”¹ä¸ºç¡®è®¤æµï¼šå…ˆæŠŠ queries å›æ˜¾å¹¶æºå¸¦ CONFIRM_WEB è´Ÿè½½ï¼Œç­‰å¾…ç”¨æˆ·æŒ‡ä»¤
		var payload string
		if len(decision.Queries) > 0 {
			b, _ := json.Marshal(decision.Queries)
			payload = fmt.Sprintf("æ£€æµ‹åˆ°è¯¥é—®é¢˜å¯èƒ½éœ€è¦è”ç½‘æ£€ç´¢ã€‚\nå»ºè®®æŸ¥è¯¢å…³é”®ä¿¡æ¯ï¼š\n%s\n\nå¦‚éœ€ç»§ç»­ï¼Œè¯·å›å¤ /search æˆ– ç»§ç»­è”ç½‘ã€‚\nCONFIRM_WEB:%s",
				processNewLine(cleanTextBlock(string(b))),
				fmt.Sprintf("{\"question\": %q, \"queries\": %s}", a.info.qParsed, string(b)))
		} else {
			payload = fmt.Sprintf("æ£€æµ‹åˆ°è¯¥é—®é¢˜å¯èƒ½éœ€è¦è”ç½‘æ£€ç´¢ã€‚\nå¦‚éœ€ç»§ç»­ï¼Œè¯·å›å¤ /search æˆ– ç»§ç»­è”ç½‘ã€‚\nCONFIRM_WEB:%s",
				fmt.Sprintf("{\"question\": %q, \"queries\": []}", a.info.qParsed))
		}
		finalHistory := append(history, openai.Messages{Role: "user", Content: a.info.qParsed})
		finalHistory = append(finalHistory, openai.Messages{Role: "assistant", Content: payload})
		a.handler.sessionCache.SetMsg(*a.info.sessionId, finalHistory)
		if len(finalHistory) == 2 {
			sendNewTopicCard(*a.ctx, a.info.sessionId, a.info.msgId, payload)
			return false
		}
		if err := replyMsg(*a.ctx, payload, a.info.msgId); err != nil {
			replyMsg(*a.ctx, fmt.Sprintf("ğŸ¤–ï¸ï¼šæ¶ˆæ¯æœºå™¨äººæ‘†çƒ‚äº†ï¼Œè¯·ç¨åå†è¯•ï½\né”™è¯¯ä¿¡æ¯: %v", err), a.info.msgId)
			return false
		}
		return true
	}

	// NeedWeb == false: directly return final answer from decision.Answer
	answer := decision.Answer
	if answer == "" {
		// Safety fallback: run a normal completion to produce an answer
		msg := append(history, openai.Messages{Role: "user", Content: a.info.qParsed})
		completions, err2 := a.handler.gpt.Completions(msg)
		if err2 != nil {
			replyMsg(*a.ctx, fmt.Sprintf("ğŸ¤–ï¸ï¼šæ¶ˆæ¯æœºå™¨äººæ‘†çƒ‚äº†ï¼Œè¯·ç¨åå†è¯•ï½\né”™è¯¯ä¿¡æ¯: %v", err2), a.info.msgId)
			return false
		}
		// debug: print direct-fallback raw output
		fmt.Println("[OpenAI Direct Fallback] raw:", completions.Content)
		msg = append(msg, completions)
		a.handler.sessionCache.SetMsg(*a.info.sessionId, msg)
		if len(msg) == 2 {
			sendNewTopicCard(*a.ctx, a.info.sessionId, a.info.msgId, completions.Content)
			return false
		}
		if err = replyMsg(*a.ctx, completions.Content, a.info.msgId); err != nil {
			replyMsg(*a.ctx, fmt.Sprintf("ğŸ¤–ï¸ï¼šæ¶ˆæ¯æœºå™¨äººæ‘†çƒ‚äº†ï¼Œè¯·ç¨åå†è¯•ï½\né”™è¯¯ä¿¡æ¯: %v", err), a.info.msgId)
			return false
		}
		return true
	}
	// debug: print direct answer
	fmt.Println("[OpenAI Direct Answer]:", answer)

	// Append assistant answer to history and reply
	finalHistory := append(history, openai.Messages{Role: "user", Content: a.info.qParsed})
	finalHistory = append(finalHistory, openai.Messages{Role: "assistant", Content: answer})
	a.handler.sessionCache.SetMsg(*a.info.sessionId, finalHistory)
	if len(finalHistory) == 2 {
		sendNewTopicCard(*a.ctx, a.info.sessionId, a.info.msgId, answer)
		return false
	}
	if err := replyMsg(*a.ctx, answer, a.info.msgId); err != nil {
		replyMsg(*a.ctx, fmt.Sprintf("ğŸ¤–ï¸ï¼šæ¶ˆæ¯æœºå™¨äººæ‘†çƒ‚äº†ï¼Œè¯·ç¨åå†è¯•ï½\né”™è¯¯ä¿¡æ¯: %v", err), a.info.msgId)
		return false
	}
	return true
}
